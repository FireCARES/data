{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcel loading\n",
    "\n",
    "Given a set of parcels (assumes GDB format) from the parcel provider, this notebook will load individual features (from the parcel provider -- currently each feature-type is a county) into respective tables in postgres.  Unfortunately due to the nature of the OpenFileGDB driver provided by GDAL (also experienced w/ the ESRI FileGDB driver) loading into a single homogeneous table was not working and loading all feature types (eg. separate tables for each feature type) would also error out at about 30% of parcels loaded.\n",
    "\n",
    "This notebook also assumes that the feature tables for every feature have already been created (eg. as the result of a failed bulk load).  Empty tables will be backfilled with feature data (in chunks of 50 counties at a time) and also compare feature counts per table to the parcel provider's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "conn = pg.connect('service=parcels')\n",
    "conn_str = os.environ.get('PARCELS_CONNECTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load into individual parcel tables in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"select table_name from information_schema.tables where table_schema = 'core_logic_2018'\")\n",
    "    res = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [x[0] for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    for t in tables:\n",
    "        cur.execute(\"select count(1) from core_logic_2018.{}\".format(t))\n",
    "        res.append({'table': t, 'count': cur.fetchone()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do = filter(lambda x: x['count'] == 0, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_list in chunks(map(lambda x: x['table'], to_do), 50):\n",
    "    tables = ' '.join(table_list)\n",
    "    print \"Loading {}\".format(tables)\n",
    "    !GDAL_MAX_DATASET_POOL_SIZE=100 ogr2ogr -f \"PostgreSQL\" PG:\"$conn_str\" ut_parcel_premium.gdb/ $tables -progress -lco SCHEMA=core_logic_2018 -lco OVERWRITE=yes --config PG_USE_COPY YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./parcel-meta.csv\")\n",
    "\n",
    "for r in res:\n",
    "    row = df[df.Filename == r['table']]\n",
    "    if int(row['Records']) != r['count']:\n",
    "        display('Mismatch on parcel: {} csv count {} != db count of {}'.format(row['Filename'], row['Records'], r['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate into single table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create destination parcels table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute('CREATE TABLE public.parcels_2018 AS TABLE public.parcels WITH NO DATA;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "insert into public.parcels_2018 (ogc_fid, wkb_geometry, parcel_id, state_code, cnty_code, apn, \n",
    "            apn2, addr, city, state, zip, plus, std_addr, std_city, std_state, \n",
    "            std_zip, std_plus, fips_code, unfrm_apn, apn_seq_no, frm_apn, \n",
    "            orig_apn, acct_no, census_tr, block_nbr, lot_nbr, land_use, m_home_ind, \n",
    "            prop_ind, own_cp_ind, tot_val, lan_val, imp_val, tot_val_cd, \n",
    "            lan_val_cd, assd_val, assd_lan, assd_imp, mkt_val, mkt_lan, mkt_imp, \n",
    "            appr_val, appr_lan, appr_imp, tax_amt, tax_yr, assd_yr, ubld_sq_ft, \n",
    "            bld_sq_ft, liv_sq_ft, gr_sq_ft, yr_blt, eff_yr_blt, bedrooms, \n",
    "            rooms, bld_code, bld_imp_cd, condition, constr_typ, ext_walls, \n",
    "            quality, story_nbr, bld_units, units_nbr)\n",
    "select {}, shape, parcel_id, state_code, cnty_code, apn, \n",
    "            apn2, addr, city, state, zip, plus, std_addr, std_city, std_state, \n",
    "            std_zip, std_plus, fips_code, unfrm_apn, apn_seq_no, frm_apn, \n",
    "            orig_apn, acct_no, census_tr, block_nbr, lot_nbr, land_use, m_home_ind, \n",
    "            prop_ind, own_cp_ind, tot_val, lan_val, imp_val, tot_val_cd, \n",
    "            lan_val_cd, assd_val, assd_lan, assd_imp, mkt_val, mkt_lan, mkt_imp, \n",
    "            appr_val, appr_lan, appr_imp, tax_amt, tax_yr, assd_yr, ubld_sq_ft, \n",
    "            bld_sq_ft, liv_sq_ft, gr_sq_ft, yr_blt, eff_yr_blt, bedrooms, \n",
    "            rooms, bld_code, bld_imp_cd, condition, constr_typ, ext_walls, \n",
    "            quality, story_nbr, bld_units, units_nbr\n",
    "from core_logic_2018.{}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    for r in res[50:]:\n",
    "        with conn.cursor() as c:\n",
    "            c.execute(\"select count(1) from information_schema.columns where table_name = %(table)s and table_schema = 'core_logic_2018' and column_name = 'objectid'\",\n",
    "                      r)\n",
    "            id_col = 'objectid' if c.fetchone()[0] == 1 else 'ogc_fid'\n",
    "            c.execute(sql.format(id_col, r['table']))\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (census_tr COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (\"substring\"(census_tr::text, 0, 7) COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (city COLLATE pg_catalog.\"default\", state COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (fips_code COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (land_use COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE UNIQUE INDEX ON public.parcels_2018 USING btree (parcel_id);\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING gist (wkb_geometry);\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (state_code COLLATE pg_catalog.\"default\", \"substring\"(census_tr::text, 0, 7) COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (state COLLATE pg_catalog.\"default\");\"\"\")\n",
    "    c.execute(\"\"\"CREATE INDEX ON public.parcels_2018 USING btree (story_nbr);\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
